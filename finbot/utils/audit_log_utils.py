"""Utilities for querying and analyzing audit logs.

This module provides tools for reading, filtering, and analyzing
audit logs generated by the structured logging system.
"""

from __future__ import annotations

import json
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Any

import pandas as pd


@dataclass
class AuditLogQuery:
    """Query parameters for filtering audit logs.

    Attributes:
        operation_type: Filter by operation type
        operation: Filter by specific operation name
        status: Filter by operation status
        start_time: Filter by start time (ISO format or datetime)
        end_time: Filter by end time (ISO format or datetime)
        user: Filter by user
        min_duration_ms: Minimum duration in milliseconds
        max_duration_ms: Maximum duration in milliseconds
        has_errors: Filter to entries with errors only
    """

    operation_type: str | None = None
    operation: str | None = None
    status: str | None = None
    start_time: str | datetime | None = None
    end_time: str | datetime | None = None
    user: str | None = None
    min_duration_ms: float | None = None
    max_duration_ms: float | None = None
    has_errors: bool = False


@dataclass
class AuditLogSummary:
    """Summary statistics for audit logs.

    Attributes:
        total_operations: Total number of operations
        successful_operations: Number of successful operations
        failed_operations: Number of failed operations
        partial_operations: Number of partial operations
        avg_duration_ms: Average operation duration
        operations_by_type: Count of operations by type
        operations_by_status: Count of operations by status
        error_messages: Unique error messages
    """

    total_operations: int = 0
    successful_operations: int = 0
    failed_operations: int = 0
    partial_operations: int = 0
    avg_duration_ms: float = 0.0
    operations_by_type: dict[str, int] = field(default_factory=dict)
    operations_by_status: dict[str, int] = field(default_factory=dict)
    error_messages: list[str] = field(default_factory=list)


class AuditLogReader:
    """Reader for parsing and querying audit logs.

    Examples:
        Basic usage:
        >>> reader = AuditLogReader()
        >>> entries = reader.read_all()

        Query with filters:
        >>> query = AuditLogQuery(operation_type="backtest", status="failure", start_time="2024-01-01")
        >>> failed_backtests = reader.query(query)

        Generate summary:
        >>> summary = reader.generate_summary(operation_type="simulation")
    """

    def __init__(self, log_dir: Path | None = None, logger_name: str = "finbot"):
        """Initialize audit log reader.

        Args:
            log_dir: Directory containing log files (default: finbot/data/logs)
            logger_name: Logger name (determines log file name)
        """
        if log_dir is None:
            # Lazy import to avoid circular dependency
            from finbot.constants.path_constants import LOGS_DIR

            log_dir = LOGS_DIR

        self.log_file = log_dir / f"{logger_name}.log.jsonl"

        if not self.log_file.exists():
            raise FileNotFoundError(f"Log file not found: {self.log_file}")

    def read_all(self) -> list[dict[str, Any]]:
        """Read all audit log entries.

        Returns:
            List of audit log entries (dictionaries)
        """
        entries = []

        with open(self.log_file) as f:
            for line in f:
                try:
                    entry = json.loads(line.strip())
                    # Filter to audit logs only
                    if entry.get("audit_log"):
                        entries.append(entry)
                except json.JSONDecodeError:
                    continue

        return entries

    def query(self, query: AuditLogQuery | None = None, **kwargs) -> list[dict[str, Any]]:
        """Query audit logs with filters.

        Args:
            query: AuditLogQuery object with filter criteria
            **kwargs: Alternative way to specify query parameters

        Returns:
            List of matching audit log entries

        Example:
            >>> reader.query(operation_type="backtest", status="failure")
        """
        # Allow passing query params as kwargs
        if query is None:
            query = AuditLogQuery(**kwargs)

        all_entries = self.read_all()
        filtered_entries = []

        for entry in all_entries:
            if not self._matches_query(entry, query):
                continue
            filtered_entries.append(entry)

        return filtered_entries

    def _matches_time_range(self, entry: dict[str, Any], query: AuditLogQuery) -> bool:
        """Check if entry falls within the query time range."""
        if not (query.start_time or query.end_time):
            return True
        entry_time = entry.get("audit_timestamp")
        if not entry_time:
            return False
        entry_dt = datetime.fromisoformat(entry_time)
        if query.start_time:
            start_dt = (
                query.start_time if isinstance(query.start_time, datetime) else datetime.fromisoformat(query.start_time)
            )
            if entry_dt < start_dt:
                return False
        if query.end_time:
            end_dt = query.end_time if isinstance(query.end_time, datetime) else datetime.fromisoformat(query.end_time)
            if entry_dt > end_dt:
                return False
        return True

    def _matches_query(self, entry: dict[str, Any], query: AuditLogQuery) -> bool:
        """Check if entry matches query criteria.

        Args:
            entry: Log entry
            query: Query criteria

        Returns:
            True if entry matches all query criteria
        """
        if query.operation_type and entry.get("operation_type") != query.operation_type:
            return False
        if query.operation and entry.get("operation") != query.operation:
            return False
        if query.status and entry.get("status") != query.status:
            return False
        if query.user and entry.get("user") != query.user:
            return False
        if not self._matches_time_range(entry, query):
            return False
        if query.min_duration_ms is not None and entry.get("duration_ms", 0) < query.min_duration_ms:
            return False
        if query.max_duration_ms is not None and entry.get("duration_ms", float("inf")) > query.max_duration_ms:
            return False
        return not (query.has_errors and not entry.get("errors", []))

    def generate_summary(
        self,
        query: AuditLogQuery | None = None,
        **kwargs,
    ) -> AuditLogSummary:
        """Generate summary statistics for audit logs.

        Args:
            query: Optional query to filter entries
            **kwargs: Alternative way to specify query parameters

        Returns:
            AuditLogSummary with statistics

        Example:
            >>> summary = reader.generate_summary(operation_type="backtest")
            >>> print(f"Success rate: {summary.successful_operations / summary.total_operations:.1%}")
        """
        entries = self.query(query, **kwargs) if query or kwargs else self.read_all()

        summary = AuditLogSummary()
        summary.total_operations = len(entries)

        durations = []
        error_messages = set()

        for entry in entries:
            # Count by status
            status = entry.get("status")
            if status == "success":
                summary.successful_operations += 1
            elif status == "failure":
                summary.failed_operations += 1
            elif status == "partial":
                summary.partial_operations += 1

            summary.operations_by_status[status] = summary.operations_by_status.get(status, 0) + 1

            # Count by type
            op_type = entry.get("operation_type", "unknown")
            summary.operations_by_type[op_type] = summary.operations_by_type.get(op_type, 0) + 1

            # Collect durations
            if "duration_ms" in entry:
                durations.append(entry["duration_ms"])

            # Collect error messages
            errors = entry.get("errors", [])
            error_messages.update(errors)

        # Calculate average duration
        if durations:
            summary.avg_duration_ms = sum(durations) / len(durations)

        summary.error_messages = sorted(error_messages)

        return summary

    def to_dataframe(self, query: AuditLogQuery | None = None, **kwargs) -> pd.DataFrame:
        """Convert audit logs to pandas DataFrame for analysis.

        Args:
            query: Optional query to filter entries
            **kwargs: Alternative way to specify query parameters

        Returns:
            DataFrame with audit log data

        Example:
            >>> df = reader.to_dataframe(operation_type="backtest")
            >>> df.groupby("status")["duration_ms"].mean()
        """
        entries = self.query(query, **kwargs) if query or kwargs else self.read_all()

        if not entries:
            return pd.DataFrame()

        # Flatten nested structures for DataFrame
        flattened = []
        for entry in entries:
            flat_entry = {
                "timestamp": entry.get("audit_timestamp"),
                "operation": entry.get("operation"),
                "operation_type": entry.get("operation_type"),
                "status": entry.get("status"),
                "duration_ms": entry.get("duration_ms"),
                "user": entry.get("user"),
                "has_errors": bool(entry.get("errors")),
                "error_count": len(entry.get("errors", [])),
            }
            flattened.append(flat_entry)

        df = pd.DataFrame(flattened)

        # Convert timestamp to datetime
        if "timestamp" in df.columns:
            df["timestamp"] = pd.to_datetime(df["timestamp"])

        return df

    def export_to_csv(
        self,
        output_path: Path | str,
        query: AuditLogQuery | None = None,
        **kwargs,
    ):
        """Export audit logs to CSV file.

        Args:
            output_path: Path to output CSV file
            query: Optional query to filter entries
            **kwargs: Alternative way to specify query parameters

        Example:
            >>> reader.export_to_csv("failed_backtests.csv", status="failure")
        """
        df = self.to_dataframe(query, **kwargs)
        df.to_csv(output_path, index=False)

    def export_to_parquet(
        self,
        output_path: Path | str,
        query: AuditLogQuery | None = None,
        **kwargs,
    ):
        """Export audit logs to parquet file.

        Args:
            output_path: Path to output parquet file
            query: Optional query to filter entries
            **kwargs: Alternative way to specify query parameters

        Example:
            >>> reader.export_to_parquet("audit_logs.parquet")
        """
        df = self.to_dataframe(query, **kwargs)
        df.to_parquet(output_path, index=False)
